@InProceedings{10.1007/978-3-319-13695-0_74,
author="Riesen, Kaspar
and Brodi{\'{c}}, Darko
and Milivojevi{\'{c}}, Zoran N.
and Maluckov, {\v{C}}edomir A.",
editor="Ioannides, Marinos
and Magnenat-Thalmann, Nadia
and Fink, Eleanor
and {\v{Z}}arni{\'{c}}, Roko
and Yen, Alex-Yianing
and Quak, Ewald",
title="Graph Based Keyword Spotting in Medieval Slavic Documents -- A Project Outline",
booktitle="Digital Heritage. Progress in Cultural Heritage: Documentation, Preservation, and Protection",
year="2014",
publisher="Springer International Publishing",
address="Cham",
pages="724--731",
abstract="The objective of the planned project is to adapt a recent graph matching framework developed by the applicant to the problem of keyword spotting. The overall question to be answered is whether or not graph based representation and especially graph matching techniques can be beneficially employed for keyword spotting. For testing this novel keyword spotting framework, the Miroslav Gospels will be used. Miroslav Gospels is a 362-page illuminated manuscript Gospel Book on parchment with very rich decorations, which was inscribed on UNESCO's Memory of the World Register in recognition of its historical value. It is one of the oldest surviving documents written in Old Church Slavonic. We plan to make the extracted word graphs from the Miroslav Gospels publicly available for further developments in graph based keyword spotting.",
isbn="978-3-319-13695-0"
}
@INPROCEEDINGS{7333824,
  author={Giotis, Angelos P. and Sfikas, Giorgos and Nikou, Christophoros and Gatos, Basilis},
  booktitle={2015 13th International Conference on Document Analysis and Recognition (ICDAR)}, 
  title={Shape-based word spotting in handwritten document images}, 
  year={2015},
  volume={},
  number={},
  pages={561-565},
  doi={10.1109/ICDAR.2015.7333824}
}

@InProceedings{10.1007/978-3-031-36616-1_15,
author="Gurav, Aniket
and Jensen, Joakim
and Krishnan, Narayanan C.
and Chanda, Sukalpa",
editor="Pertusa, Antonio
and Gallego, Antonio Javier
and S{\'a}nchez, Joan Andreu
and Domingues, In{\^e}s",
title="ResPho(SC)Net: A Zero-Shot Learning Framework for Norwegian Handwritten Word Image Recognition",
booktitle="Pattern Recognition and Image Analysis",
year="2023",
publisher="Springer Nature Switzerland",
address="Cham",
pages="182--196",
abstract="Recent advances in deep Convolutional Neural Networks (CNNs) have established them as a premier technique for a wide range of classification tasks, including object recognition, object detection, image segmentation, face recognition, and medical image analysis. However, a significant drawback of utilizing CNNs is the requirement for a large amount of annotated data, which may not be feasible in the context of historical document analysis. In light of this, we present a novel CNN-based architecture ResPho(SC)Net, to recognize handwritten word images in a zero-shot learning framework. Our method proposes a modified version of the Phosc(Net) architecture with a much lesser number of trainable parameters. Experiments were conducted on word images from two languages (Norwegian and English) and encouraging results were obtained.",
isbn="978-3-031-36616-1"
}
@article{SOUIBGUI202243,
title = {Few shots are all you need: A progressive learning approach for low resource handwritten text recognition},
journal = {Pattern Recognition Letters},
volume = {160},
pages = {43-49},
year = {2022},
issn = {0167-8655},
doi = {https://doi.org/10.1016/j.patrec.2022.06.003},
url = {https://www.sciencedirect.com/science/article/pii/S016786552200191X},
author = {Mohamed Ali Souibgui and Alicia Fornés and Yousri Kessentini and Beáta Megyesi},
keywords = {Handwritten text recognition, Few-shot learning, Unsupervised progressive learning, Ciphered manuscripts},
abstract = {Handwritten text recognition in low resource scenarios, such as manuscripts with rare alphabets, is a challenging problem. In this paper, we propose a few-shot learning-based handwriting recognition approach that significantly reduces the human annotation process, by requiring only a few images of each alphabet symbols. The method consists of detecting all the symbols of a given alphabet in a textline image and decoding the obtained similarity scores to the final sequence of transcribed symbols. Our model is first pretrained on synthetic line images generated from an alphabet, which could differ from the alphabet of the target domain. A second training step is then applied to reduce the gap between the source and the target data. Since this retraining would require annotation of thousands of handwritten symbols together with their bounding boxes, we propose to avoid such human effort through an unsupervised progressive learning approach that automatically assigns pseudo-labels to the unlabeled data. The evaluation on different datasets shows that our model can lead to competitive results with a significant reduction in human effort. The code will be publicly available in the following repository: https://github.com/dali92002/HTRbyMatching}
}
@INPROCEEDINGS{627095,
  author={Keaton, P. and Greenspan, H. and Goodman, R.},
  booktitle={Proceedings Workshop on Document Image Analysis (DIA'97)}, 
  title={Keyword spotting for cursive document retrieval}, 
  year={1997},
  volume={},
  number={},
  pages={74-81},
  doi={10.1109/DIA.1997.627095}}
@INPROCEEDINGS{1211511,
  author={Rath, T.M. and Manmatha, R.},
  booktitle={2003 IEEE Computer Society Conference on Computer Vision and Pattern Recognition, 2003. Proceedings.}, 
  title={Word image matching using dynamic time warping}, 
  year={2003},
  volume={2},
  number={},
  pages={II-II},
  doi={10.1109/CVPR.2003.1211511}}
@INPROCEEDINGS{7333824,
  author={Giotis, Angelos P. and Sfikas, Giorgos and Nikou, Christophoros and Gatos, Basilis},
  booktitle={2015 13th International Conference on Document Analysis and Recognition (ICDAR)}, 
  title={Shape-based word spotting in handwritten document images}, 
  year={2015},
  volume={},
  number={},
  pages={561-565},
  doi={10.1109/ICDAR.2015.7333824}}
@ARTICLE{8378004,
  author={Retsinas, George and Louloudis, Georgios and Stamatopoulos, Nikolaos and Gatos, Basilis},
  journal={IEEE Transactions on Pattern Analysis and Machine Intelligence}, 
  title={Efficient Learning-Free Keyword Spotting}, 
  year={2019},
  volume={41},
  number={7},
  pages={1587-1600},
  doi={10.1109/TPAMI.2018.2845880}}
@inproceedings{retsinas2021from,
  title={From Seq2Seq to Handwritten Word Embeddings},
  author={Retsinas, George and Sfikas, Giorgos and Nikou, Christophoros and Maragos, Petros},
  booktitle={British Machine Vision Conference (BMVC)},
  year={2021},
}
﻿@Article{Krishnan2023,
author={Krishnan, Praveen
and Dutta, Kartik
and Jawahar, C. V.},
title={HWNet v3: a joint embedding framework for recognition and retrieval of handwritten text},
journal={International Journal on Document Analysis and Recognition (IJDAR)},
year={2023},
month={Jan},
day={28},
abstract={Learning an efficient label embedding framework for word images enables effective word spotting of handwritten documents. In this work, we propose different schemes of label embedding for word images using deep neural architectures and their representations. We refer to our first scheme as the two-stage label embedding technique which projects both word images and their corresponding textual strings into a common subspace. We further introduce an end-to-end label embedding scheme using deep neural architecture which simplifies the embedding process and reports state-of-the-art performance for the task of word spotting and recognition. We also validate the role of synthetic data as a complementary modality to further enhance the embedding process. On the challenging IAM handwritten dataset, we report an mAP of 0.9753 for query-by-string-based word spotting, while under lexicon-based word recognition, our proposed method reports 1.67 and 3.62 character and word error rates, respectively. We also present the detailed ablation study on various variants of our end-to-end embedding architecture and perform analysis under varying embedding sizes. We further validate the embedding scheme on degraded printed document datasets from both Latin and Indic scripts.},
issn={1433-2825},
doi={10.1007/s10032-022-00423-6},
url={https://doi.org/10.1007/s10032-022-00423-6}
}
@misc{jemni2023stkeys,
      title={ST-KeyS: Self-Supervised Transformer for Keyword Spotting in Historical Handwritten Documents}, 
      author={Sana Khamekhem Jemni and Sourour Ammar and Mohamed Ali Souibgui and Yousri Kessentini and Abbas Cheddad},
      year={2023},
      eprint={2303.03127},
      archivePrefix={arXiv},
      primaryClass={cs.CV}
}
@InProceedings{10.1007/978-3-031-41676-7_26,
author="Retsinas, George
and Sfikas, Giorgos
and Nikou, Christophoros",
editor="Fink, Gernot A.
and Jain, Rajiv
and Kise, Koichi
and Zanibbi, Richard",
title="Keyword Spotting Simplified: A Segmentation-Free Approach Using Character Counting and CTC Re-scoring",
booktitle="Document Analysis and Recognition - ICDAR 2023",
year="2023",
publisher="Springer Nature Switzerland",
address="Cham",
pages="446--464",
abstract="Recent advances in segmentation-free keyword spotting borrow from state-of-the-art object detection systems to simultaneously propose a word bounding box proposal mechanism and compute a corresponding representation. Contrary to the norm of such methods that rely on complex and large DNN models, we propose a novel segmentation-free system that efficiently scans a document image to find rectangular areas that include the query information. The underlying model is simple and compact, predicting character occurrences over rectangular areas through an implicitly learned scale map, trained on word-level annotated images. The proposed document scanning is then performed using this character counting in a cost-effective manner via integral images and binary search. Finally, the retrieval similarity by character counting is refined by a pyramidal representation and a CTC-based re-scoring algorithm, fully utilizing the trained CNN model. Experimental validation on two widely-used datasets shows that our method achieves state-of-the-art results outperforming the more complex alternatives, despite the simplicity of the underlying model.",
isbn="978-3-031-41676-7"
}

@InProceedings{10.1007/978-3-031-06555-2_26,
author="Sfikas, Giorgos
and Retsinas, George
and Giotis, Angelos P.
and Gatos, Basilis
and Nikou, Christophoros",
editor="Uchida, Seiichi
and Barney, Elisa
and Eglin, V{\'e}ronique",
title="Keyword Spotting with Quaternionic ResNet: Application to Spotting in Greek Manuscripts",
booktitle="Document Analysis Systems",
year="2022",
publisher="Springer International Publishing",
address="Cham",
pages="382--396",
abstract="Quaternionized versions of standard (real-valued) neural network layers have shown to lead to networks that are sparse and as effective as their real-valued counterparts. In this work, we explore their usefulness in the context of the Keyword Spotting task. Tests on a collection of manuscripts written in modern Greek show that the proposed quaternionic ResNet achieves excellent performance using only a small fraction of the memory footprint of its real-valued counterpart. Code is available at https://github.com/sfikas/quaternion-resnet-kws.",
isbn="978-3-031-06555-2"
}
﻿@Article{Cascianelli2022,
author={Cascianelli, Silvia
and Cornia, Marcella
and Baraldi, Lorenzo
and Cucchiara, Rita},
title={Boosting modern and historical handwritten text recognition with deformable convolutions},
journal={International Journal on Document Analysis and Recognition (IJDAR)},
year={2022},
month={Sep},
day={01},
volume={25},
number={3},
pages={207-217},
abstract={Handwritten Text Recognition (HTR) in free-layout pages is a challenging image understanding task that can provide a relevant boost to the digitization of handwritten documents and reuse of their content. The task becomes even more challenging when dealing with historical documents due to the variability of the writing style and degradation of the page quality. State-of-the-art HTR approaches typically couple recurrent structures for sequence modeling with Convolutional Neural Networks for visual feature extraction. Since convolutional kernels are defined on fixed grids and focus on all input pixels independently while moving over the input image, this strategy disregards the fact that handwritten characters can vary in shape, scale, and orientation even within the same document and that the ink pixels are more relevant than the background ones. To cope with these specific HTR difficulties, we propose to adopt deformable convolutions, which can deform depending on the input at hand and better adapt to the geometric variations of the text. We design two deformable architectures and conduct extensive experiments on both modern and historical datasets. Experimental results confirm the suitability of deformable convolutions for the HTR task.},
issn={1433-2825},
doi={10.1007/s10032-022-00401-y},
url={https://doi.org/10.1007/s10032-022-00401-y}
}

@INPROCEEDINGS{8270021,
  author={Sfikas, Giorgos and Retsinas, George and Gatos, Basilis},
  booktitle={2017 14th IAPR International Conference on Document Analysis and Recognition (ICDAR)}, 
  title={A PHOC Decoder for Lexicon-Free Handwritten Word Recognition}, 
  year={2017},
  volume={01},
  number={},
  pages={513-518},
  doi={10.1109/ICDAR.2017.90}}

@inproceedings{ameri2017keyword,
  title={Keyword spotting in historical documents based on handwriting graphs and Hausdorff edit distance},
  author={Ameri, M and Stauffer, Michael and Riesen, Kaspar and Bui, T and Fischer, Andreas},
  booktitle={International graphonomics society conference},
  pages={105--108},
  year={2017}
}
@inproceedings{yousfi2021keyword,
  title={Keyword Spotting in Modern Handwritten Documents Using oBIFs},
  author={Yousfi, Douaa and Gattal, Abdeljalil and Djeddi, Chawki and Siddiqi, Imran and Bensefia, Ameur},
  booktitle={Mediterranean Conference on Pattern Recognition and Artificial Intelligence},
  pages={240--250},
  year={2021},
  organization={Springer}
}
@article{omayio2023word,
  title={Word spotting and character recognition of handwritten Hindi scripts by Integral Histogram of Oriented Displacement (IHOD) descriptor},
  author={Omayio, Enock Osoro and Indu, Sreedevi and Panda, Jeebananda},
  journal={Multimedia Tools and Applications},
  pages={1--28},
  year={2023},
  publisher={Springer}
}
@article{kundu2021hough,
  title={Hough transform-based angular features for learning-free handwritten keyword spotting},
  author={Kundu, Subhranil and Malakar, Samir and Geem, Zong Woo and Moon, Yoon Young and Singh, Pawan Kumar and Sarkar, Ram},
  journal={Sensors},
  volume={21},
  number={14},
  pages={4648},
  year={2021},
  publisher={MDPI}
}
@inproceedings{stauffer2016graph,
  title={Graph-based keyword spotting in historical handwritten documents},
  author={Stauffer, Michael and Fischer, Andreas and Riesen, Kaspar},
  booktitle={Structural, Syntactic, and Statistical Pattern Recognition: Joint IAPR International Workshop, S+ SSPR 2016, M{\'e}rida, Mexico, November 29-December 2, 2016, Proceedings},
  pages={564--573},
  year={2016},
  organization={Springer}
}
@article{banerjee2022z,
  title={Z-Transform-Based Profile Matching to Develop a Learning-Free Keyword Spotting Method for Handwritten Document Images},
  author={Banerjee, Debanshu and Bhowal, Pratik and Malakar, Samir and Cuevas, Erik and P{\'e}rez-Cisneros, Marco and Sarkar, Ram},
  journal={International Journal of Computational Intelligence Systems},
  volume={15},
  number={1},
  pages={93},
  year={2022},
  publisher={Springer}
}
@article{rusakov2018expolring,
  title={Expolring architectures for cnn-based word spotting},
  author={Rusakov, Eugen and Sudholt, Sebastian and Wolf, Fabian and Fink, Gernot A},
  journal={arXiv preprint arXiv:1806.10866},
  year={2018}
}
@article{stauffer2020filters,
  title={Filters for graph-based keyword spotting in historical handwritten documents},
  author={Stauffer, Michael and Fischer, Andreas and Riesen, Kaspar},
  journal={Pattern Recognition Letters},
  volume={134},
  pages={125--134},
  year={2020},
  publisher={Elsevier}
}